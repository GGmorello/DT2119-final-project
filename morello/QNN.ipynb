{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Local Definitions\n",
    "from data_generator import generate_mel_spectrogram\n",
    "from models import CNN_Model, Dense_Model, AttentionRNN_Model\n",
    "from helper_q_tool import generate_quantum_speech, plot_accuracy_loss, display_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Set the GPU to be used\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# Generate a unique timestamp for current run\n",
    "current_time_stamp = time.strftime(\"%m%d_%H%M\")\n",
    "\n",
    "# Paths\n",
    "training_audio_path = 'dataset/'\n",
    "data_save_path = \"data_quantum/\"  # Data saving folder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "speech_commands = [\"bed\",\"cat\",\"dog\",\"five\",\"happy\",\"left\",\"marvin\",\"sheila\",\"six\",\"stop\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# parser.add_argument(\"--eps\", type = int, default = 30, help = \"Epochs\")\n",
    "# parser.add_argument(\"--bsize\", type = int, default = 16, help = \"Batch Size\")\n",
    "# parser.add_argument(\"--sr\", type = int, default = 16000, help = \"Sampling Rate for input Speech\")\n",
    "# parser.add_argument(\"--net\", type = int, default = 1, help = \"(0) Dense Model, (1) U-Net RNN Attention\")\n",
    "# parser.add_argument(\"--mel\", type = int, default = 0, help = \"(0) Load Demo Features, (1) Extra Mel Features\")\n",
    "# parser.add_argument(\"--quanv\", type = int, default = 0, help = \"(0) Load Demo Features, (1) Extra Mel Features\")\n",
    "# parser.add_argument(\"--port\", type = int, default = 100, help = \"(1/N) data ratio for encoding \")\n",
    "epochs=30\n",
    "batch_size=16\n",
    "sampling_rate=16000\n",
    "model_type='UNET'\n",
    "mel_option='MEL'\n",
    "quantum_option='MEL'\n",
    "partition_ratio=100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def generate_training_data(labels, training_audio_path, sampling_rate, partition_ratio):\n",
    "    all_wave, all_label = generate_mel_spectrogram(labels, training_audio_path, sampling_rate, partition_ratio)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(all_label)\n",
    "    classes = list(label_encoder.classes_)\n",
    "    y = keras.utils.to_categorical(y, num_classes=len(labels))\n",
    "\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "        np.array(all_wave), np.array(y), stratify=y, test_size=0.2, random_state=777, shuffle=True\n",
    "    )\n",
    "    height_feature, width_feature, _ = x_train[0].shape\n",
    "    np.save(data_save_path + \"n_x_train_speech.npy\", x_train)\n",
    "    np.save(data_save_path + \"n_x_test_speech.npy\", x_valid)\n",
    "    np.save(data_save_path + \"n_y_train_speech.npy\", y_train)\n",
    "    np.save(data_save_path + \"n_y_test_speech.npy\", y_valid)\n",
    "    print(\"=== Feature Shape:\", height_feature, width_feature)\n",
    "\n",
    "    return x_train, x_valid, y_train, y_valid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def generate_quantum_features(x_train, x_valid, kernel_radius):\n",
    "    print(\"Kernel Radius =\", kernel_radius)\n",
    "    q_train, q_valid = generate_quantum_speech(x_train, x_valid, kernel_radius)\n",
    "\n",
    "    np.save(data_save_path + \"q_train.npy\", q_train)\n",
    "    np.save(data_save_path + \"q_test.npy\", q_valid)\n",
    "\n",
    "    return q_train, q_valid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "Generate or load data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:11<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Feature Shape: 60 126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid, y_train, y_valid = generate_training_data(speech_commands, training_audio_path, sampling_rate, partition_ratio)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "x_train = np.load(data_save_path + \"n_x_train_speech.npy\")\n",
    "x_valid = np.load(data_save_path + \"n_x_test_speech.npy\")\n",
    "y_train = np.load(data_save_path + \"n_y_train_speech.npy\")\n",
    "y_valid = np.load(data_save_path + \"n_y_test_speech.npy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "Generate or load quantum features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Radius = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Quantum pre-processing of train Speech::  15%|█▍        | 22/149 [02:28<14:33,  6.88s/it]"
     ]
    }
   ],
   "source": [
    "q_train, q_valid = generate_quantum_features(x_train, x_valid, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data_quantum/q_train.npy'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [9]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m q_train \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_save_path\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mq_train.npy\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m q_valid \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mload(data_save_path \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mq_test.npy\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniforge3/envs/DT2119-final-project/lib/python3.10/site-packages/numpy/lib/npyio.py:407\u001B[0m, in \u001B[0;36mload\u001B[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001B[0m\n\u001B[1;32m    405\u001B[0m     own_fid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    406\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 407\u001B[0m     fid \u001B[38;5;241m=\u001B[39m stack\u001B[38;5;241m.\u001B[39menter_context(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mos_fspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    408\u001B[0m     own_fid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    410\u001B[0m \u001B[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001B[39;00m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'data_quantum/q_train.npy'"
     ]
    }
   ],
   "source": [
    "q_train = np.load(data_save_path + \"q_train.npy\")\n",
    "q_valid = np.load(data_save_path + \"q_test.npy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, min_delta=0.0001)\n",
    "checkpoint = ModelCheckpoint('checkpoints/best_demo.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pick a model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "Classical CNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielemorello/miniforge3/envs/DT2119-final-project/lib/python3.10/site-packages/keras/src/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "cnn_model = CNN_Model(x_train.shape[0], x_train.shape[1], speech_commands)\n",
    "cnn_model.summary()\n",
    "cnn_history = cnn_model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpoint],\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_valid,y_valid)\n",
    ")\n",
    "cnn_model.save('checkpoints/' + current_time_stamp + '_cnn.keras')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "Quantum CNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "quantum_cnn_model = CNN_Model(q_train.shape[0], q_train.shape[1], speech_commands)\n",
    "quantum_cnn_model.summary()\n",
    "quantum_cnn_history = quantum_cnn_model.fit(\n",
    "    x=q_train,\n",
    "    y=y_train,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpoint],\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(q_valid,y_valid)\n",
    ")\n",
    "quantum_cnn_model.save('checkpoints/' + current_time_stamp + '_quantum_cnn.keras')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "Classsical Attention RNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "attrnn_model = AttentionRNN_Model(x_train[0], speech_commands)\n",
    "attrnn_model.summary()\n",
    "attrnn_history = attrnn_model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpoint],\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_valid,y_valid)\n",
    ")\n",
    "attrnn_model.save('checkpoints/' + current_time_stamp + '_rnn.keras')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "Quantum Attention RNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "quantum_attrnn_model = AttentionRNN_Model(q_train[0], speech_commands)\n",
    "quantum_attrnn_model.summary()\n",
    "quantum_attrnn_history = quantum_attrnn_model.fit(\n",
    "    x=q_train,\n",
    "    y=y_train,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpoint],\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(q_valid,y_valid)\n",
    ")\n",
    "quantum_attrnn_model.save('checkpoints/' + current_time_stamp + '_quantum_attrnn.keras')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Batch Size:  16\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Batch Size: \", batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_speech(x_train, q_train, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_speech(x_train, q_train, False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_accuracy_loss(attrnn_history, quantum_attrnn_history, cnn_history, quantum_cnn_history, 'lol')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}