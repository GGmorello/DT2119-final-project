{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "from pennylane import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from data_generator import gen_mel\n",
    "from models import cnn_Model, dense_Model, attrnn_Model\n",
    "from helper_q_tool import gen_qspeech, plot_acc_loss, show_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "data_ix = time.strftime(\"%m%d_%H%M\")\n",
    "train_audio_path = 'dataset/'\n",
    "SAVE_PATH = \"data_quantum/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "labels = [\n",
    "    'left', 'go', 'yes', 'down', 'up', 'on', 'right', 'no', 'off', 'stop',\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# parser.add_argument(\"--eps\", type = int, default = 30, help = \"Epochs\")\n",
    "# parser.add_argument(\"--bsize\", type = int, default = 16, help = \"Batch Size\")\n",
    "# parser.add_argument(\"--sr\", type = int, default = 16000, help = \"Sampling Rate for input Speech\")\n",
    "# parser.add_argument(\"--net\", type = int, default = 1, help = \"(0) Dense Model, (1) U-Net RNN Attention\")\n",
    "# parser.add_argument(\"--mel\", type = int, default = 0, help = \"(0) Load Demo Features, (1) Extra Mel Features\")\n",
    "# parser.add_argument(\"--quanv\", type = int, default = 0, help = \"(0) Load Demo Features, (1) Extra Mel Features\")\n",
    "# parser.add_argument(\"--port\", type = int, default = 100, help = \"(1/N) data ratio for encoding \")\n",
    "epochs=30\n",
    "batch_size=16\n",
    "sampling_rate=16000\n",
    "network='UNET'\n",
    "mel='MEL'\n",
    "quanv='MEL'\n",
    "port=100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def gen_train(labels, train_audio_path, sr, port):\n",
    "    all_wave, all_label = gen_mel(labels, train_audio_path, sr, port)\n",
    "\n",
    "    label_enconder = LabelEncoder()\n",
    "    y = label_enconder.fit_transform(all_label)\n",
    "    classes = list(label_enconder.classes_)\n",
    "    y = keras.utils.to_categorical(y, num_classes=len(labels))\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(np.array(all_wave),np.array(y),stratify=y,test_size = 0.2,random_state=777,shuffle=True)\n",
    "    h_feat, w_feat, _ = x_train[0].shape\n",
    "    np.save(SAVE_PATH + \"n_x_train_speech.npy\", x_train)\n",
    "    np.save(SAVE_PATH + \"n_x_test_speech.npy\", x_valid)\n",
    "    np.save(SAVE_PATH + \"n_y_train_speech.npy\", y_train)\n",
    "    np.save(SAVE_PATH + \"n_y_test_speech.npy\", y_valid)\n",
    "    print(\"===== Shape\", h_feat, w_feat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def gen_quanv(x_train, x_valid, kr):\n",
    "    print(\"Kernal = \", kr)\n",
    "    q_train, q_valid = gen_qspeech(x_train, x_valid, kr)\n",
    "\n",
    "    np.save(SAVE_PATH + \"demo_t1.npy\", q_train)\n",
    "    np.save(SAVE_PATH + \"demo_t2.npy\", q_valid)\n",
    "\n",
    "    return q_train, q_valid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "melspectrogram() takes 0 positional arguments but 1 positional argument (and 4 keyword-only arguments) were given",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [13]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mel \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMEL\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m----> 2\u001B[0m     x_train, x_valid, y_train, y_valid \u001B[38;5;241m=\u001B[39m \u001B[43mgen_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_audio_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msampling_rate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mport\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m mel \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDEMO\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m      4\u001B[0m     x_train \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mload(SAVE_PATH \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx_train_demo.npy\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Input \u001B[0;32mIn [11]\u001B[0m, in \u001B[0;36mgen_train\u001B[0;34m(labels, train_audio_path, sr, port)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgen_train\u001B[39m(labels, train_audio_path, sr, port):\n\u001B[0;32m----> 2\u001B[0m     all_wave, all_label \u001B[38;5;241m=\u001B[39m \u001B[43mgen_mel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_audio_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mport\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m     label_enconder \u001B[38;5;241m=\u001B[39m LabelEncoder()\n\u001B[1;32m      5\u001B[0m     y \u001B[38;5;241m=\u001B[39m label_enconder\u001B[38;5;241m.\u001B[39mfit_transform(all_label)\n",
      "File \u001B[0;32m~/PycharmProjects/DT2119-final-project/qnn/Decentralizing Feature Extraction with Quantum Convolutional Neural Network for Automatic Speech Recognition /QuantumSpeech-QCNN/data_generator.py:24\u001B[0m, in \u001B[0;36mgen_mel\u001B[0;34m(labels, train_audio_path, sr, port)\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num \u001B[38;5;241m%\u001B[39m port \u001B[38;5;241m==\u001B[39m\u001B[38;5;241m0\u001B[39m:   \u001B[38;5;66;03m# take 1/port samples\u001B[39;00m\n\u001B[1;32m     23\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m(\u001B[38;5;28mlen\u001B[39m(y)\u001B[38;5;241m==\u001B[39m sr) :\n\u001B[0;32m---> 24\u001B[0m         mel_feat \u001B[38;5;241m=\u001B[39m \u001B[43mlibrosa\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmelspectrogram\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_fft\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1024\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhop_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m128\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpower\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_mels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m60\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfmin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m40.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfmax\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msr\u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     25\u001B[0m         all_wave\u001B[38;5;241m.\u001B[39mappend(np\u001B[38;5;241m.\u001B[39mexpand_dims(mel_feat, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m))\n\u001B[1;32m     26\u001B[0m         all_label\u001B[38;5;241m.\u001B[39mappend(label)\n",
      "\u001B[0;31mTypeError\u001B[0m: melspectrogram() takes 0 positional arguments but 1 positional argument (and 4 keyword-only arguments) were given"
     ]
    }
   ],
   "source": [
    "if mel == 'MEL':\n",
    "    x_train, x_valid, y_train, y_valid = gen_train(labels, train_audio_path, sampling_rate, port)\n",
    "elif mel == 'DEMO':\n",
    "    x_train = np.load(SAVE_PATH + \"x_train_demo.npy\")\n",
    "    x_valid = np.load(SAVE_PATH + \"x_test_demo.npy\")\n",
    "    y_train = np.load(SAVE_PATH + \"y_train_demo.npy\")\n",
    "    y_valid = np.load(SAVE_PATH + \"y_test_demo.npy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernal =  2\n",
      "Quantum pre-processing of train Speech:\n",
      "89/1500        \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m quanv \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMEL\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m----> 2\u001B[0m     q_train, q_valid \u001B[38;5;241m=\u001B[39m \u001B[43mgen_quanv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_valid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m mel \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDEMO\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m      4\u001B[0m     q_train \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mload(SAVE_PATH \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mq_train_demo.npy\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36mgen_quanv\u001B[0;34m(x_train, x_valid, kr)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgen_quanv\u001B[39m(x_train, x_valid, kr):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKernal = \u001B[39m\u001B[38;5;124m\"\u001B[39m, kr)\n\u001B[0;32m----> 3\u001B[0m     q_train, q_valid \u001B[38;5;241m=\u001B[39m \u001B[43mgen_qspeech\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_valid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m     np\u001B[38;5;241m.\u001B[39msave(SAVE_PATH \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdemo_t1.npy\u001B[39m\u001B[38;5;124m\"\u001B[39m, q_train)\n\u001B[1;32m      6\u001B[0m     np\u001B[38;5;241m.\u001B[39msave(SAVE_PATH \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdemo_t2.npy\u001B[39m\u001B[38;5;124m\"\u001B[39m, q_valid)\n",
      "File \u001B[0;32m~/PycharmProjects/DT2119-final-project/qnn/Decentralizing Feature Extraction with Quantum Convolutional Neural Network for Automatic Speech Recognition /QuantumSpeech-QCNN/helper_q_tool.py:64\u001B[0m, in \u001B[0;36mgen_qspeech\u001B[0;34m(x_train, x_valid, kr)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx, img \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(x_train):\n\u001B[1;32m     63\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m        \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(idx \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mlen\u001B[39m(x_train)), end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 64\u001B[0m     q_train\u001B[38;5;241m.\u001B[39mappend(\u001B[43mquanv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkr\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     65\u001B[0m q_train \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(q_train)\n\u001B[1;32m     67\u001B[0m q_valid \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/PycharmProjects/DT2119-final-project/qnn/Decentralizing Feature Extraction with Quantum Convolutional Neural Network for Automatic Speech Recognition /QuantumSpeech-QCNN/helper_q_tool.py:49\u001B[0m, in \u001B[0;36mquanv\u001B[0;34m(image, kr)\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, h_feat, kr):\n\u001B[1;32m     47\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, w_feat, kr):\n\u001B[1;32m     48\u001B[0m         \u001B[38;5;66;03m# Process a squared 2x2 region of the image with a quantum circuit\u001B[39;00m\n\u001B[0;32m---> 49\u001B[0m         q_results \u001B[38;5;241m=\u001B[39m \u001B[43mcircuit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     50\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;66;43;03m# kernal 3 ## phi=[image[j, k, 0], image[j, k + 1, 0], image[j, k + 2, 0], image[j + 1, k, 0], \u001B[39;49;00m\n\u001B[1;32m     51\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;66;43;03m# image[j + 1, k + 1, 0], image[j + 1, k +2 , 0],image[j+2, k, 0], image[j+2, k+1, 0], image[j+2, k+2, 0]]\u001B[39;49;00m\n\u001B[1;32m     52\u001B[0m \u001B[43m            \u001B[49m\u001B[43mphi\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m[\u001B[49m\u001B[43mj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimage\u001B[49m\u001B[43m[\u001B[49m\u001B[43mj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimage\u001B[49m\u001B[43m[\u001B[49m\u001B[43mj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimage\u001B[49m\u001B[43m[\u001B[49m\u001B[43mj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m         \u001B[38;5;66;03m# Assign expectation values to different channels of the output pixel (j/2, k/2)\u001B[39;00m\n\u001B[1;32m     55\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_w):\n",
      "File \u001B[0;32m~/miniforge3/envs/DT2119-final-project/lib/python3.10/site-packages/pennylane/qnode.py:867\u001B[0m, in \u001B[0;36mQNode.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    865\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexecute_kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmode\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    866\u001B[0m \u001B[38;5;66;03m# pylint: disable=unexpected-keyword-arg\u001B[39;00m\n\u001B[0;32m--> 867\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mqml\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    868\u001B[0m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtape\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    870\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgradient_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgradient_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    871\u001B[0m \u001B[43m    \u001B[49m\u001B[43minterface\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minterface\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    872\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgradient_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgradient_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    873\u001B[0m \u001B[43m    \u001B[49m\u001B[43moverride_shots\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moverride_shots\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    874\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    875\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    877\u001B[0m res \u001B[38;5;241m=\u001B[39m res[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    879\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m old_interface \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/miniforge3/envs/DT2119-final-project/lib/python3.10/site-packages/pennylane/interfaces/execution.py:407\u001B[0m, in \u001B[0;36mexecute\u001B[0;34m(tapes, device, gradient_fn, interface, grad_on_execution, gradient_kwargs, cache, cachesize, max_diff, override_shots, expand_fn, max_expansion, device_batch_transform)\u001B[0m\n\u001B[1;32m    403\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m batch_fn(res)\n\u001B[1;32m    405\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m gradient_fn \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbackprop\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m interface \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    406\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m batch_fn(\n\u001B[0;32m--> 407\u001B[0m         \u001B[43mqml\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minterfaces\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcache_execute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    408\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbatch_execute\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_tuple\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexpand_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexpand_fn\u001B[49m\n\u001B[1;32m    409\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtapes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    410\u001B[0m     )\n\u001B[1;32m    412\u001B[0m \u001B[38;5;66;03m# the default execution function is batch_execute\u001B[39;00m\n\u001B[1;32m    413\u001B[0m execute_fn \u001B[38;5;241m=\u001B[39m qml\u001B[38;5;241m.\u001B[39minterfaces\u001B[38;5;241m.\u001B[39mcache_execute(batch_execute, cache, expand_fn\u001B[38;5;241m=\u001B[39mexpand_fn)\n",
      "File \u001B[0;32m~/miniforge3/envs/DT2119-final-project/lib/python3.10/site-packages/pennylane/interfaces/execution.py:204\u001B[0m, in \u001B[0;36mcache_execute.<locals>.wrapper\u001B[0;34m(tapes, **kwargs)\u001B[0m\n\u001B[1;32m    200\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (res, []) \u001B[38;5;28;01mif\u001B[39;00m return_tuple \u001B[38;5;28;01melse\u001B[39;00m res\n\u001B[1;32m    202\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    203\u001B[0m     \u001B[38;5;66;03m# execute all unique tapes that do not exist in the cache\u001B[39;00m\n\u001B[0;32m--> 204\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexecution_tapes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    206\u001B[0m final_res \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    208\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, tape \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(tapes):\n",
      "File \u001B[0;32m~/miniforge3/envs/DT2119-final-project/lib/python3.10/site-packages/pennylane/interfaces/execution.py:130\u001B[0m, in \u001B[0;36mcache_execute.<locals>.fn\u001B[0;34m(tapes, **kwargs)\u001B[0m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfn\u001B[39m(tapes: Sequence[QuantumTape], \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):  \u001B[38;5;66;03m# pylint: disable=function-redefined\u001B[39;00m\n\u001B[1;32m    129\u001B[0m     tapes \u001B[38;5;241m=\u001B[39m [expand_fn(tape) \u001B[38;5;28;01mfor\u001B[39;00m tape \u001B[38;5;129;01min\u001B[39;00m tapes]\n\u001B[0;32m--> 130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43moriginal_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtapes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/DT2119-final-project/lib/python3.10/contextlib.py:79\u001B[0m, in \u001B[0;36mContextDecorator.__call__.<locals>.inner\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds):\n\u001B[1;32m     78\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_recreate_cm():\n\u001B[0;32m---> 79\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/DT2119-final-project/lib/python3.10/site-packages/pennylane/_qubit_device.py:588\u001B[0m, in \u001B[0;36mQubitDevice.batch_execute\u001B[0;34m(self, circuits)\u001B[0m\n\u001B[1;32m    583\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m circuit \u001B[38;5;129;01min\u001B[39;00m circuits:\n\u001B[1;32m    584\u001B[0m     \u001B[38;5;66;03m# we need to reset the device here, else it will\u001B[39;00m\n\u001B[1;32m    585\u001B[0m     \u001B[38;5;66;03m# not start the next computation in the zero state\u001B[39;00m\n\u001B[1;32m    586\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreset()\n\u001B[0;32m--> 588\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcircuit\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    589\u001B[0m     results\u001B[38;5;241m.\u001B[39mappend(res)\n\u001B[1;32m    591\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtracker\u001B[38;5;241m.\u001B[39mactive:\n",
      "File \u001B[0;32m~/miniforge3/envs/DT2119-final-project/lib/python3.10/site-packages/pennylane/_qubit_device.py:318\u001B[0m, in \u001B[0;36mQubitDevice.execute\u001B[0;34m(self, circuit, **kwargs)\u001B[0m\n\u001B[1;32m    315\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_validity(circuit\u001B[38;5;241m.\u001B[39moperations, circuit\u001B[38;5;241m.\u001B[39mobservables)\n\u001B[1;32m    317\u001B[0m \u001B[38;5;66;03m# apply all circuit operations\u001B[39;00m\n\u001B[0;32m--> 318\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcircuit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moperations\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrotations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_diagonalizing_gates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcircuit\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    320\u001B[0m \u001B[38;5;66;03m# generate computational basis samples\u001B[39;00m\n\u001B[1;32m    321\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshots \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m circuit\u001B[38;5;241m.\u001B[39mis_sampled:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "if quanv == 'MEL':\n",
    "    q_train, q_valid = gen_quanv(x_train, x_valid, 2)\n",
    "elif mel == 'DEMO':\n",
    "    q_train = np.load(SAVE_PATH + \"q_train_demo.npy\")\n",
    "    q_valid = np.load(SAVE_PATH + \"q_test_demo.npy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min',\n",
    "                           verbose=1, patience=10, min_delta=0.0001)\n",
    "\n",
    "checkpoint = ModelCheckpoint('checkpoints/best_demo.hdf5', monitor='val_acc',\n",
    "                             verbose=1, save_best_only=True, mode='max')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielemorello/miniforge3/envs/DT2119-final-project/lib/python3.10/site-packages/keras/src/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "if network == 'DENSE':\n",
    "    model = dense_Model(x_train[0], labels)\n",
    "elif network == 'UNET':\n",
    "    model = attrnn_Model(q_train[0], labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 30, 63, 4)]          0         []                            \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 30, 63, 4)            16        ['input_2[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " permute (Permute)           (None, 63, 30, 4)            0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 63, 30, 16)           336       ['permute[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 63, 30, 16)           64        ['conv2d[0][0]']              \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 63, 30, 32)           2592      ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 63, 30, 32)           128       ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 63, 30, 16)           2576      ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 63, 30, 16)           64        ['conv2d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 63, 30, 32)           0         ['batch_normalization_1[0][0]'\n",
      "                                                                    , 'batch_normalization_3[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 63, 30, 1)            161       ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 63, 30, 1)            4         ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " squeeze_last_dim (Lambda)   (None, 63, 30)               0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " bidirectional (Bidirection  (None, 63, 128)              48640     ['squeeze_last_dim[0][0]']    \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirecti  (None, 63, 128)              98816     ['bidirectional[0][0]']       \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " lambda (Lambda)             (None, 128)                  0         ['bidirectional_1[0][0]']     \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 128)                  16512     ['lambda[0][0]']              \n",
      "                                                                                                  \n",
      " dot (Dot)                   (None, 63)                   0         ['dense[0][0]',               \n",
      "                                                                     'bidirectional_1[0][0]']     \n",
      "                                                                                                  \n",
      " attSoftmax (Softmax)        (None, 63)                   0         ['dot[0][0]']                 \n",
      "                                                                                                  \n",
      " dot_1 (Dot)                 (None, 128)                  0         ['attSoftmax[0][0]',          \n",
      "                                                                     'bidirectional_1[0][0]']     \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 64)                   8256      ['dot_1[0][0]']               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 32)                   2080      ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " output (Dense)              (None, 10)                   330       ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 180575 (705.37 KB)\n",
      "Trainable params: 180437 (704.83 KB)\n",
      "Non-trainable params: 138 (552.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 16:31:39.976543: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:693] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" model: \"0\" frequency: 2400 num_cores: 10 environment { key: \"cpu_instruction_set\" value: \"ARM NEON\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 16384 l2_cache_size: 524288 l3_cache_size: 524288 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/94 [============================>.] - ETA: 0s - loss: 2.1579 - accuracy: 0.1956"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 16:31:45.633629: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:693] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" model: \"0\" frequency: 2400 num_cores: 10 environment { key: \"cpu_instruction_set\" value: \"ARM NEON\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 16384 l2_cache_size: 524288 l3_cache_size: 524288 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 9s 60ms/step - loss: 2.1557 - accuracy: 0.1947 - val_loss: 2.4969 - val_accuracy: 0.1100\n",
      "Epoch 2/30\n",
      "94/94 [==============================] - ETA: 0s - loss: 1.2208 - accuracy: 0.5800WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 5s 56ms/step - loss: 1.2208 - accuracy: 0.5800 - val_loss: 1.4702 - val_accuracy: 0.4920\n",
      "Epoch 3/30\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.6388 - accuracy: 0.7829WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 5s 56ms/step - loss: 0.6357 - accuracy: 0.7840 - val_loss: 1.0988 - val_accuracy: 0.6500\n",
      "Epoch 4/30\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.4659 - accuracy: 0.8360WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 5s 57ms/step - loss: 0.4663 - accuracy: 0.8353 - val_loss: 0.8860 - val_accuracy: 0.7240\n",
      "Epoch 5/30\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8757WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 5s 57ms/step - loss: 0.3867 - accuracy: 0.8747 - val_loss: 0.6841 - val_accuracy: 0.7720\n",
      "Epoch 6/30\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.3153 - accuracy: 0.9012WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.3140 - accuracy: 0.9013 - val_loss: 0.5910 - val_accuracy: 0.8280\n",
      "Epoch 7/30\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.3151 - accuracy: 0.8945WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 5s 55ms/step - loss: 0.3135 - accuracy: 0.8953 - val_loss: 1.7589 - val_accuracy: 0.5800\n",
      "Epoch 8/30\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.1918 - accuracy: 0.9362WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 5s 58ms/step - loss: 0.1906 - accuracy: 0.9367 - val_loss: 1.5950 - val_accuracy: 0.6220\n",
      "Epoch 9/30\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.2154 - accuracy: 0.9274WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 5s 57ms/step - loss: 0.2163 - accuracy: 0.9273 - val_loss: 0.6161 - val_accuracy: 0.8280\n",
      "Epoch 10/30\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.1810 - accuracy: 0.9353WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 6s 62ms/step - loss: 0.1810 - accuracy: 0.9353 - val_loss: 3.0415 - val_accuracy: 0.3600\n",
      "Epoch 11/30\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.1946 - accuracy: 0.9362WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 5s 55ms/step - loss: 0.1932 - accuracy: 0.9367 - val_loss: 0.5735 - val_accuracy: 0.8120\n",
      "Epoch 12/30\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.1526 - accuracy: 0.9433WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 5s 59ms/step - loss: 0.1526 - accuracy: 0.9433 - val_loss: 0.4627 - val_accuracy: 0.8600\n",
      "Epoch 13/30\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.1157 - accuracy: 0.9651WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 5s 56ms/step - loss: 0.1156 - accuracy: 0.9647 - val_loss: 0.5407 - val_accuracy: 0.8240\n",
      "Epoch 14/30\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0705 - accuracy: 0.9758WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 6s 64ms/step - loss: 0.0704 - accuracy: 0.9760 - val_loss: 0.5279 - val_accuracy: 0.8680\n",
      "Epoch 15/30\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0721 - accuracy: 0.9724WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 5s 57ms/step - loss: 0.0724 - accuracy: 0.9720 - val_loss: 0.5197 - val_accuracy: 0.8640\n",
      "Epoch 16/30\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.1252 - accuracy: 0.9590WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 5s 58ms/step - loss: 0.1259 - accuracy: 0.9587 - val_loss: 0.6913 - val_accuracy: 0.8200\n",
      "Epoch 17/30\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.1289 - accuracy: 0.9527WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 5s 55ms/step - loss: 0.1289 - accuracy: 0.9527 - val_loss: 0.7179 - val_accuracy: 0.8220\n",
      "Epoch 18/30\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.1689 - accuracy: 0.9382WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 5s 56ms/step - loss: 0.1680 - accuracy: 0.9387 - val_loss: 0.4576 - val_accuracy: 0.8720\n",
      "Epoch 19/30\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.1162 - accuracy: 0.9630WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 5s 58ms/step - loss: 0.1163 - accuracy: 0.9627 - val_loss: 1.6831 - val_accuracy: 0.6860\n",
      "Epoch 20/30\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0688 - accuracy: 0.9778WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 6s 59ms/step - loss: 0.0684 - accuracy: 0.9780 - val_loss: 0.4928 - val_accuracy: 0.8600\n",
      "Epoch 21/30\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.1057 - accuracy: 0.9664WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 6s 62ms/step - loss: 0.1057 - accuracy: 0.9667 - val_loss: 0.5159 - val_accuracy: 0.8660\n",
      "Epoch 22/30\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0876 - accuracy: 0.9724WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.0870 - accuracy: 0.9727 - val_loss: 0.9321 - val_accuracy: 0.7740\n",
      "Epoch 23/30\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0596 - accuracy: 0.9798WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.0605 - accuracy: 0.9793 - val_loss: 0.5290 - val_accuracy: 0.8400\n",
      "Epoch 24/30\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.1107 - accuracy: 0.9603WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 6s 62ms/step - loss: 0.1104 - accuracy: 0.9607 - val_loss: 0.7476 - val_accuracy: 0.8260\n",
      "Epoch 25/30\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.1268 - accuracy: 0.9570WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 6s 60ms/step - loss: 0.1273 - accuracy: 0.9567 - val_loss: 0.5431 - val_accuracy: 0.8820\n",
      "Epoch 26/30\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0934 - accuracy: 0.9698WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 6s 63ms/step - loss: 0.0927 - accuracy: 0.9700 - val_loss: 0.5524 - val_accuracy: 0.8580\n",
      "Epoch 27/30\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0932 - accuracy: 0.9677WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 5s 58ms/step - loss: 0.0928 - accuracy: 0.9680 - val_loss: 0.6796 - val_accuracy: 0.8320\n",
      "Epoch 28/30\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0548 - accuracy: 0.9819WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 6s 60ms/step - loss: 0.0544 - accuracy: 0.9820 - val_loss: 0.5680 - val_accuracy: 0.8760\n",
      "Epoch 29/30\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0336 - accuracy: 0.9899WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 5s 56ms/step - loss: 0.0333 - accuracy: 0.9900 - val_loss: 0.5508 - val_accuracy: 0.8620\n",
      "Epoch 30/30\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0290 - accuracy: 0.9892WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "94/94 [==============================] - 5s 57ms/step - loss: 0.0288 - accuracy: 0.9893 - val_loss: 0.5441 - val_accuracy: 0.8760\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=q_train,\n",
    "    y=y_train,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpoint],\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(q_valid,y_valid)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielemorello/miniforge3/envs/DT2119-final-project/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('checkpoints/'+ data_ix + '_demo.hdf5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Batch Size:  16\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Batch Size: \", batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}